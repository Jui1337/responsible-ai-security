{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          2         2   26     -1      2      0      0   \n",
      "2   3      90000    2          2         2   34      0      0      0      0   \n",
      "3   4      50000    2          2         1   37      0      0      0      0   \n",
      "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...          0          0          0         0       689         0   \n",
      "1  ...       3272       3455       3261         0      1000      1000   \n",
      "2  ...      14331      14948      15549      1518      1500      1000   \n",
      "3  ...      28314      28959      29547      2000      2019      1200   \n",
      "4  ...      20940      19146      19131      2000     36681     10000   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
      "0         0         0         0                           1  \n",
      "1      1000         0      2000                           1  \n",
      "2      1000      1000      5000                           0  \n",
      "3      1100      1069      1000                           0  \n",
      "4      9000       689       679                           0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"/home/jui/thesis-code/data/credit_card_clients.xls\")\n",
    "\n",
    "# Display the first few rows of the dataframe to verify it loaded correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          1         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          1         2   26     -1      2      0      0   \n",
      "2   3      90000    2          1         2   34      0      0      0      0   \n",
      "3   4      50000    2          1         1   37      0      0      0      0   \n",
      "4   5      50000    1          1         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...          0          0          0         0       689         0   \n",
      "1  ...       3272       3455       3261         0      1000      1000   \n",
      "2  ...      14331      14948      15549      1518      1500      1000   \n",
      "3  ...      28314      28959      29547      2000      2019      1200   \n",
      "4  ...      20940      19146      19131      2000     36681     10000   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
      "0         0         0         0                           1  \n",
      "1      1000         0      2000                           1  \n",
      "2      1000      1000      5000                           0  \n",
      "3      1100      1069      1000                           0  \n",
      "4      9000       689       679                           0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df['EDUCATION'] = df['EDUCATION'].replace({1: 1, 2: 1, 3: 2, 4: 3})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    95919\n",
      "-1    59055\n",
      " 2    18964\n",
      " 1     3722\n",
      " 3     1430\n",
      " 4      453\n",
      " 7      218\n",
      " 5      137\n",
      " 6       74\n",
      " 8       28\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each unique value across all PAY_* columns\n",
    "value_counts = df[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']].stack().value_counts()\n",
    "# List of columns to modify\n",
    "pay_columns = ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "\n",
    "# Replace -2 with -1\n",
    "df[pay_columns] = df[pay_columns].replace({-2:-1})\n",
    "\n",
    "# Count occurrences of each unique value across PAY_* columns\n",
    "value_counts = df[pay_columns].stack().value_counts()\n",
    "\n",
    "# Print result\n",
    "print(value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 25, 35, 45, 55, 70, float('inf')]  # Define bin edges\n",
    "labels = [1, 2, 3, 4, 5, 6]  # Assign category labels\n",
    "\n",
    "df['AGE'] = pd.cut(df['AGE'], bins=bins, labels=labels, right=False).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MARRIAGE'] = df['MARRIAGE'].replace({0: 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    18112\n",
       "1    11888\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    18112\n",
      "1    18112\n",
      "Name: SEX, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from raimitigations.dataprocessing import Rebalance\n",
    "\n",
    "rebalance = Rebalance(\n",
    "\t\t\t\tdf=df,\n",
    "\t\t\t\trebalance_col='SEX',\n",
    "\t\t\t\tk_neighbors=6,\n",
    "\t\t\t\tverbose=False\n",
    "\t\t\t)\n",
    "df = rebalance.fit_resample()\n",
    "print(df['SEX'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost as xgb\n",
    "from packaging import version\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def split_label(dataset, target_feature):\n",
    "    X = dataset.drop([target_feature], axis=1)\n",
    "    y = dataset[[target_feature]]\n",
    "    return X, y\n",
    "\n",
    "# Handle different scikit-learn versions for OneHotEncoder parameters\n",
    "if version.parse(sklearn.__version__) < version.parse('1.2'):\n",
    "    ohe_params = {\"sparse\": False}\n",
    "else:\n",
    "    ohe_params = {\"sparse_output\": False}\n",
    "\n",
    "def create_classification_pipeline(X):\n",
    "    pipe_cfg = {\n",
    "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\n",
    "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
    "    }\n",
    "    num_pipe = Pipeline([ \n",
    "        ('num_imputer', SimpleImputer(strategy='median')),\n",
    "        ('num_scaler', StandardScaler())\n",
    "    ])\n",
    "    cat_pipe = Pipeline([\n",
    "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', **ohe_params))\n",
    "    ])\n",
    "    feat_pipe = ColumnTransformer([\n",
    "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\n",
    "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\n",
    "    ])\n",
    "\n",
    "    # Using XGBClassifier with GPU support\n",
    "    pipeline = Pipeline(steps=[('preprocessor', feat_pipe),\n",
    "                            ('model', xgb.XGBClassifier(\n",
    "                                tree_method='hist',  # Use hist for GPU training\n",
    "                                random_state=10,\n",
    "                                n_jobs=-1  # Use all available CPU cores for pre-processing\n",
    "                            ))])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8366828621908127\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      7304\n",
      "           1       0.64      0.36      0.46      1752\n",
      "\n",
      "    accuracy                           0.84      9056\n",
      "   macro avg       0.75      0.66      0.68      9056\n",
      "weighted avg       0.82      0.84      0.82      9056\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_feature = 'default payment next month'\n",
    "categorical_features = []\n",
    "\n",
    "# Split data into features and target\n",
    "X, y = split_label(df, target_feature)\n",
    "\n",
    "# Split data into train and test sets (80% training, 20% testing)\n",
    "X_train_og, X_test_og, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=40)\n",
    "\n",
    "# Create classification pipeline\n",
    "pipeline = create_classification_pipeline(X_train_og)\n",
    "\n",
    "# Convert target labels to numpy arrays for fitting\n",
    "y_train = y_train[target_feature].to_numpy()\n",
    "y_test = y_test[target_feature].to_numpy()\n",
    "\n",
    "# Train the model using the pipeline\n",
    "model = pipeline.fit(X_train_og, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test_og)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{class_report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raiwidgets import ResponsibleAIDashboard\n",
    "from responsibleai import RAIInsights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from responsibleai.feature_metadata import FeatureMetadata\n",
    "# Set up feature metadata for RAIInsights\n",
    "feature_metadata = FeatureMetadata(categorical_features=categorical_features, dropped_features=[])\n",
    "\n",
    "# Add the target feature back to the datasets\n",
    "X_train_og_with_target = X_train_og.copy()\n",
    "X_train_og_with_target[target_feature] = y_train\n",
    "\n",
    "X_test_og_with_target = X_test_og.copy()\n",
    "X_test_og_with_target[target_feature] = y_test\n",
    "X_test_og_with_target = X_test_og_with_target.sample(n=1000, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, pass these modified DataFrames to RAIInsights\n",
    "rai_insights = RAIInsights(model, X_train_og_with_target, X_test_og_with_target, target_feature, 'classification', feature_metadata=feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretability\n",
    "rai_insights.explainer.add()\n",
    "# Error Analysis\n",
    "rai_insights.error_analysis.add()\n",
    "# Counterfactuals: accepts total number of counterfactuals to generate, the label that they should have, and a list of \n",
    "                # strings of categorical feature names\n",
    "rai_insights.counterfactual.add(total_CFs=10, desired_class='opposite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Causal Effects\n",
      "Current Status: Generating Causal Effects.\n",
      "Current Status: Finished generating causal effects.\n",
      "Time taken: 0.0 min 1.7946818843483925e-05 sec\n",
      "================================================================================\n",
      "================================================================================\n",
      "Counterfactual\n",
      "Current Status: Generating 10 counterfactuals for 1000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [13:20<00:00,  1.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Generated 10 counterfactuals for 1000 samples.\n",
      "Time taken: 13.0 min 32.2570893028751 sec\n",
      "================================================================================\n",
      "================================================================================\n",
      "Error Analysis\n",
      "Current Status: Generating error analysis reports.\n",
      "Current Status: Finished generating error analysis reports.\n",
      "Time taken: 0.0 min 0.10575621109455824 sec\n",
      "================================================================================\n",
      "================================================================================\n",
      "Explanations\n",
      "Current Status: Explaining 23 features\n",
      "Current Status: Explained 23 features.\n",
      "Time taken: 0.0 min 0.36583710997365415 sec\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Compute: Perform all tasks (this remains CPU-bound)\n",
    "rai_insights.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponsibleAI started at http://localhost:8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<raiwidgets.responsibleai_dashboard.ResponsibleAIDashboard at 0x750c42c2a260>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResponsibleAIDashboard(rai_insights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
