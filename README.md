# Thesis-code
This research explores whether applying Microsoft's Responsible AI (RAI) principles can improve the security of machine learning models. It compares a baseline model (built without RAI considerations) with a mitigated model (enhanced using RAI tools) to evaluate impact on security and robustness of machine learning model.

Adversarial testing is conducted using the Adversarial Robustness Toolbox (ART), using two attacks customized for the tabular data.
Zeroth Order Optimization (ZOO) evasion attack
Label flip poisoning attack

Dashboards are generated using Microsoft's Responsible AI Toolbox to visualize errors, fairness metrics, and interpretability.
The dataset used is the "Default of Credit Card Clients" from the UCI Machine Learning Repository.



